{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "#### Import the data\n",
    "df = pd.read_csv('../data/text_dataset_translate.csv')\n",
    "Y = df['diag'].values\n",
    "\n",
    "# Remove CFTD and unclear diagnosis\n",
    "df['diag'].value_counts()\n",
    "# Drop the rows with unclear diagnosis\n",
    "df = df[df['diag'] != 'UNCLEAR']\n",
    "# Do the same for the X array based on the df index\n",
    "\n",
    "cv_fold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "df['diag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings, OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n",
    "\n",
    "LANGUAGE = [\"fr\", \"en\"]\n",
    "EMBEDDING_MODEL = [\"instructor\", \"openai\"]\n",
    "\n",
    "if not os.path.exists(\"../data/embeddings/instructor_en_embeddings.npy\"):\n",
    "    embeddings = HuggingFaceInstructEmbeddings(\n",
    "        query_instruction=\"Represent the medicine document for classification: \"\n",
    "    )\n",
    "    text_reports = df[\"translated_text\"].to_list()\n",
    "    embeddings_results = embeddings.embed_documents(text_reports)\n",
    "    X = np.array(embeddings_results)\n",
    "    np.save('../data/embeddings/instructor_en_embeddings.npy', X)\n",
    "\n",
    "if not os.path.exists(\"../data/embeddings/instructor_fr_embeddings.npy\"):\n",
    "    embeddings = HuggingFaceInstructEmbeddings(\n",
    "        query_instruction=\"Represent the medicine document for classification: \"\n",
    "    )\n",
    "    text_reports = df[\"text\"].to_list()\n",
    "    embeddings_results = embeddings.embed_documents(text_reports)\n",
    "    X = np.array(embeddings_results)\n",
    "    np.save('../data/embeddings/instructor_fr_embeddings.npy', X)\n",
    "\n",
    "if not os.path.exists(\"../data/embeddings/openai_en_embeddings.npy\"):\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    text_reports = df[\"translated_text\"].to_list()\n",
    "    embeddings_results = embeddings.embed_documents(text_reports)\n",
    "    X = np.array(embeddings_results)\n",
    "    np.save('../data/embeddings/openai_en_embeddings.npy', X)\n",
    "\n",
    "if not os.path.exists(\"../data/embeddings/openai_fr_embeddings.npy\"):\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    text_reports = df[\"text\"].to_list()\n",
    "    embeddings_results = embeddings.embed_documents(text_reports)\n",
    "    X = np.array(embeddings_results)\n",
    "    np.save('../data/embeddings/openai_fr_embeddings.npy', X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGE = \"fr\"\n",
    "EMBEDDING_MODEL = \"openAI\"\n",
    "\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings, OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n",
    "\n",
    "if EMBEDDING_MODEL == \"instructor\":\n",
    "    embeddings = HuggingFaceInstructEmbeddings(\n",
    "        query_instruction=\"Represent the medicine document for classification: \"\n",
    "    )\n",
    "elif EMBEDDING_MODEL == \"openai\":\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "\n",
    "if LANGUAGE == \"fr\":\n",
    "    text_reports = df[\"text\"].to_list()\n",
    "elif LANGUAGE == \"en\":\n",
    "    text_reports = df[\"translated_text\"].to_list()\n",
    "\n",
    "embeddings_results = embeddings.embed_documents(text_reports)\n",
    "X_instructor = np.array(embeddings_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load(\"../data/embeddings/openai_fr_embeddings.npy\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dummy = DummyClassifier(strategy='prior')\n",
    "cv_scores_dummy = cross_val_score(clf_dummy, X_instructor, Y, cv=cv_fold)\n",
    "print(\"Dummy Classifier Results:\")\n",
    "print(f\"All CV Scores: {cv_scores_dummy}\")\n",
    "print(f\"Mean CV Score:  {np.mean(cv_scores_dummy)}\")\n",
    "print(f\"Standard Deviation CV Score: {np.std(cv_scores_dummy)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "class DummyEstimator(BaseEstimator):\n",
    "    def fit(self): pass\n",
    "    def score(self): pass\n",
    "\n",
    "\n",
    "# Create a pipeline\n",
    "pipe = Pipeline([('clf', DummyEstimator())]) # Placeholder Estimator\n",
    "\n",
    "# Candidate learning algorithms and their hyperparameters\n",
    "search_space = [{'clf': [LogisticRegression()],\n",
    "                    'clf__max_iter': [1500]},\n",
    "                {'clf': [GaussianNB()],},\n",
    "                {'clf': [MLPClassifier()],\n",
    "                 'clf__max_iter': [2500]},\n",
    "                {'clf': [KNeighborsClassifier()],},\n",
    "                {'clf': [SVC()],},\n",
    "                {'clf': [GaussianProcessClassifier()],},\n",
    "                {'clf': [HistGradientBoostingClassifier()],},\n",
    "                {'clf': [DecisionTreeClassifier()],},\n",
    "                {'clf': [RandomForestClassifier()],},\n",
    "                {'clf': [AdaBoostClassifier()],},\n",
    "                ]\n",
    "\n",
    "# Create grid search \n",
    "gs = GridSearchCV(pipe, search_space, scoring=\"accuracy\", cv=cv_fold)\n",
    "gs.fit(X_instructor, Y)\n",
    "df_cv_search = pd.DataFrame(gs.cv_results_)\n",
    "df_cv_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "# Let's choose and optimize a MLPC\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(400,), (200,), (100,100), (200,200)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['adam'],\n",
    "    'learning_rate_init': [0.001, 0.01],\n",
    "    'max_iter': [800, 1500, 2500],\n",
    "}\n",
    "\n",
    "# Create grid search \n",
    "cls = MLPClassifier(random_state=42)\n",
    "gs_mlpc = GridSearchCV(cls, param_grid, scoring=\"accuracy\", cv=cv_fold, verbose=1)\n",
    "gs_mlpc.fit(X_instructor, Y)\n",
    "best_mlpc = gs_mlpc.best_estimator_\n",
    "df_cv_search_rf = pd.DataFrame(gs_mlpc.cv_results_)\n",
    "# Print the best parameters and score\n",
    "print(\"Best parameters:\", gs_mlpc.best_params_)\n",
    "print(\"Best score:\", gs_mlpc.best_score_)\n",
    "joblib.dump(gs_mlpc, f'../models/{EMBEDDING_MODEL}_{LANGUAGE}_gridsearch_mlpc.joblib')\n",
    "joblib.dump(best_mlpc, f'../models/{EMBEDDING_MODEL}_{LANGUAGE}_model_mlpc.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to disk & WandB\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import joblib\n",
    "\n",
    "# experiment tracking\n",
    "import wandb\n",
    "gs_mlpc = joblib.load(f'../models/{EMBEDDING_MODEL}_{LANGUAGE}_gridsearch_mlpc.joblib')\n",
    "best_mlpc = joblib.load(f'../models/{EMBEDDING_MODEL}_{LANGUAGE}_model_mlpc.joblib')\n",
    "\n",
    "# Use cross_val_predict to get predicted labels and probabilities\n",
    "y_pred = cross_val_predict(best_mlpc, X_instructor, Y, cv=cv_fold)\n",
    "y_probas = cross_val_predict(best_mlpc, X_instructor, Y, cv=cv_fold, method='predict_proba')\n",
    "# Compute classification report\n",
    "report = classification_report(Y, y_pred, target_names=best_mlpc.classes_, output_dict=True)\n",
    "\n",
    "run = wandb.init(project='myo-text-classify',\n",
    "                 config={\"embedding\": f\"{EMBEDDING_MODEL}\", \"doc_lang\": f\"{LANGUAGE}\", \"corpus\":\"complete_1704023_190reports\", \"model\":\"MLPClassifier\"})\n",
    "config = wandb.config\n",
    "best_params = gs_mlpc.best_params_\n",
    "best_score = gs_mlpc.best_score_\n",
    "best_std = gs_mlpc.cv_results_['std_test_score'][gs_mlpc.best_index_]\n",
    "balanced_accuracy_metric = balanced_accuracy_score(Y, y_pred)\n",
    "\n",
    "wandb.log({'Classification Report': report,\n",
    "           'Best Params': best_params,\n",
    "           'Best Score': best_score,\n",
    "           'CV Std Devs': best_std,\n",
    "           'Balanced Accuracy': balanced_accuracy_metric,\n",
    "        })\n",
    "wandb.sklearn.plot_confusion_matrix(Y, y_pred, best_mlpc.classes_)\n",
    "wandb.sklearn.plot_classifier(best_mlpc, X_instructor, X_instructor, Y, Y, y_pred, y_probas, labels=best_mlpc.classes_,\n",
    "                                                         model_name=f'{EMBEDDING_MODEL}_{LANGUAGE}_model', feature_names=None)\n",
    "# Create artifact for best model\n",
    "model_artifact = wandb.Artifact(f'{EMBEDDING_MODEL}_{LANGUAGE}_model_mlpc', type='model')\n",
    "# Add best estimator to artifact\n",
    "model_artifact.add_file(f'../models/{EMBEDDING_MODEL}_{LANGUAGE}_model_mlpc.joblib')\n",
    "# Log artifact to WandB\n",
    "wandb.run.log_artifact(model_artifact)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "# Let's choose and optimize a random forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'class_weight': ['balanced', 'balanced_subsample'],\n",
    "}\n",
    "\n",
    "# Create grid search \n",
    "cls_rf = RandomForestClassifier(random_state=42)\n",
    "gs_rf = GridSearchCV(cls_rf, param_grid_rf, scoring=\"accuracy\", cv=cv_fold, verbose=1)\n",
    "gs_rf.fit(X_instructor, Y)\n",
    "best_rf = gs_rf.best_estimator_\n",
    "df_cv_search_rf = pd.DataFrame(gs_rf.cv_results_)\n",
    "# Print the best parameters and score\n",
    "print(\"Best parameters:\", gs_rf.best_params_)\n",
    "print(\"Best score:\", gs_rf.best_score_)\n",
    "joblib.dump(gs_rf, f'../models/{EMBEDDING_MODEL}_{LANGUAGE}_gridsearch_rf.joblib')\n",
    "joblib.dump(best_rf, f'../models/{EMBEDDING_MODEL}_{LANGUAGE}_model_rf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to disk & WandB\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "import joblib\n",
    "\n",
    "# experiment tracking\n",
    "import wandb\n",
    "gs_rf = joblib.load(f'../models/{EMBEDDING_MODEL}_{LANGUAGE}_gridsearch_rf.joblib')\n",
    "best_rf = joblib.load(f'../models/{EMBEDDING_MODEL}_{LANGUAGE}_model_rf.joblib')\n",
    "\n",
    "# Use cross_val_predict to get predicted labels and probabilities\n",
    "y_pred = cross_val_predict(best_rf, X_instructor, Y, cv=cv_fold)\n",
    "y_probas = cross_val_predict(best_rf, X_instructor, Y, cv=cv_fold, method='predict_proba')\n",
    "# Compute classification report\n",
    "report = classification_report(Y, y_pred, target_names=best_rf.classes_, output_dict=True)\n",
    "\n",
    "run = wandb.init(project='myo-text-classify',\n",
    "                 config={\"embedding\": f\"{EMBEDDING_MODEL}\", \"doc_lang\": f\"{LANGUAGE}\", \"corpus\":\"complete_1704023_190reports\", \"model\":\"RandomForest\"})\n",
    "config = wandb.config\n",
    "best_params = gs_mlpc.best_params_\n",
    "best_score = gs_mlpc.best_score_\n",
    "best_std = gs_mlpc.cv_results_['std_test_score'][gs_mlpc.best_index_]\n",
    "balanced_accuracy_metric = balanced_accuracy_score(Y, y_pred)\n",
    "\n",
    "wandb.log({'Classification Report': report,\n",
    "           'Best Params': best_params,\n",
    "           'Best Score': best_score,\n",
    "           'CV Std Devs': best_std,\n",
    "           'Balanced Accuracy': balanced_accuracy_metric,\n",
    "        })\n",
    "wandb.sklearn.plot_confusion_matrix(Y, y_pred, best_rf.classes_)\n",
    "wandb.sklearn.plot_classifier(best_rf, X_instructor, X_instructor, Y, Y, y_pred, y_probas, labels=best_rf.classes_,\n",
    "                                                         model_name=f'{EMBEDDING_MODEL}_{LANGUAGE}_model', feature_names=None)\n",
    "# Create artifact for best model\n",
    "model_artifact = wandb.Artifact(f'{EMBEDDING_MODEL}_{LANGUAGE}_model_rf', type='model')\n",
    "# Add best estimator to artifact\n",
    "model_artifact.add_file(f'../models/{EMBEDDING_MODEL}_{LANGUAGE}_model_rf.joblib')\n",
    "# Log artifact to WandB\n",
    "wandb.run.log_artifact(model_artifact)\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
